{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Import the Random Forest classifier from scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import Gaussian Naive Bayes from scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "sample_dataset_dir = \"Sample Dataset\"\n",
    "dataset_dir = \"Dataset\"\n",
    "\n",
    "print(\"Files inside dataset_dir\")\n",
    "os.listdir(path = dataset_dir) # prints the files in the dataset directory to make sure we got the right path\n",
    "\n",
    "print(\"Files inside sample_dataset_dir\")\n",
    "os.listdir(path = sample_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to make the sample dataset which we already did\n",
    "\n",
    "#create sample dataset here\n",
    "# original_dataset_dir = dataset_dir\n",
    "\n",
    "# sample_fraction = 0.1\n",
    "\n",
    "# os.makedirs(sample_dataset_dir, exist_ok=True)\n",
    "\n",
    "# for actor_folder in os.listdir(original_dataset_dir):\n",
    "#   actor_folder_path = os.path.join(original_dataset_dir, actor_folder)\n",
    "\n",
    "#   if os.path.isdir(actor_folder_path):\n",
    "#     actor_files = [file for file in os.listdir(actor_folder_path) if file.endswith(\".wav\")]\n",
    "#     num_files_to_sample = int(sample_fraction * len(actor_files))\n",
    "\n",
    "#     sampled_files = random.sample(actor_files, num_files_to_sample)\n",
    "\n",
    "#     for file in sampled_files:\n",
    "#       src_path = os.path.join(actor_folder_path, file)\n",
    "#       dst_path = os.path.join(sample_dataset_dir, file)\n",
    "#       shutil.copy(src_path, dst_path)\n",
    "# print(\"sample dataset created with 10% of files from each actor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store metadata\n",
    "file_names, modalities, vocal_channels, emotions, intensities, statements, repetitions, actors = [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store audio features\n",
    "mean_pitches, pitch_ranges, spectral_centroids, zero_crossing_rates = [], [], [], []\n",
    "# Initialize empty lists to store additional audio features\n",
    "mfccs_mean = []\n",
    "mfccs_var = []\n",
    "chroma_mean = []\n",
    "chroma_var = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "for file in os.listdir(sample_dataset_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(sample_dataset_dir, file)\n",
    "        try:\n",
    "            # Loading audio\n",
    "            audio, sample_rate = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # Extracting pitch\n",
    "            pitches, magnitudes = librosa.piptrack(y=audio, sr=sample_rate)\n",
    "            pitch = [magnitudes[:, t].argmax() for t in range(pitches.shape[1])]\n",
    "            mean_pitch = np.mean(pitch)\n",
    "            pitch_range = max(pitch) - min(pitch)\n",
    "\n",
    "            # Extracting spectral centroid\n",
    "            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sample_rate)[0, 0]\n",
    "\n",
    "            # Extracting zero-crossing rate\n",
    "            zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)[0, 0]\n",
    "\n",
    "            # Extracting MFCCs\n",
    "            mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
    "            mfccs_mean.append(np.mean(mfccs))\n",
    "            mfccs_var.append(np.var(mfccs))\n",
    "\n",
    "            # Extracting Chroma features\n",
    "            chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n",
    "            chroma_mean.append(np.mean(chroma))\n",
    "            chroma_var.append(np.var(chroma))\n",
    "\n",
    "            mean_pitches.append(mean_pitch)\n",
    "            pitch_ranges.append(pitch_range)\n",
    "            spectral_centroids.append(spectral_centroid)\n",
    "            zero_crossing_rates.append(zero_crossing_rate)\n",
    "\n",
    "            parts = file.split(\"-\")\n",
    "            if len(parts) == 7:\n",
    "                file_names.append(file)\n",
    "                modalities.append(parts[0])\n",
    "                vocal_channels.append(parts[1])\n",
    "                emotions.append(parts[2])\n",
    "                intensities.append(parts[3])\n",
    "                statements.append(parts[4])\n",
    "                repetitions.append(parts[5])\n",
    "                actors.append(parts[6].split(\".\")[0])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_emotions = label_encoder.fit_transform(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pitch-related features\n",
    "scaler_pitch = StandardScaler()\n",
    "normalized_mean_pitches = scaler_pitch.fit_transform(np.array(mean_pitches).reshape(-1, 1))\n",
    "normalized_pitch_ranges = scaler_pitch.fit_transform(np.array(pitch_ranges).reshape(-1, 1))\n",
    "\n",
    "# Normalize additional audio features\n",
    "scaler_other = StandardScaler()\n",
    "normalized_mfccs_mean = scaler_other.fit_transform(np.array(mfccs_mean).reshape(-1, 1))\n",
    "normalized_mfccs_var = scaler_other.fit_transform(np.array(mfccs_var).reshape(-1, 1))\n",
    "normalized_chroma_mean = scaler_other.fit_transform(np.array(chroma_mean).reshape(-1, 1))\n",
    "normalized_chroma_var = scaler_other.fit_transform(np.array(chroma_var).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts lists to NumPy arrays\n",
    "spectral_centroids = np.array(spectral_centroids)\n",
    "zero_crossing_rates = np.array(zero_crossing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines all features into one array \n",
    "X = np.hstack((normalized_mean_pitches, normalized_pitch_ranges,\n",
    "               spectral_centroids.reshape(-1, 1),\n",
    "               zero_crossing_rates.reshape(-1, 1),\n",
    "               normalized_mfccs_mean.reshape(-1, 1), normalized_mfccs_var.reshape(-1, 1),\n",
    "               normalized_chroma_mean.reshape(-1, 1), normalized_chroma_var.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_emotions, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes\n",
    "nb_classifier = GaussianNB()\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Naive Bayes Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple feedforward neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(np.unique(encoded_emotions)), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
